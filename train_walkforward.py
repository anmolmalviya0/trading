"""
MARKETFORGE: Walk-Forward Training
==================================
Purged Walk-Forward Cross-Validation with meta-labeling.

Implements:
- Expanding window walk-forward CV
- Purge window = max_hold (prevents leakage)
- Nested hyperparameter tuning (in-sample only)
- Meta-labeling for trade filtering
- Probability calibration (isotonic/Platt)
- Model manifest with SHA256

Usage:
    python train_walkforward.py BTCUSDT 15m
    python train_walkforward.py --all
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json
import hashlib
import joblib
import warnings
import argparse
import yaml
from typing import Dict, List, Optional, Tuple
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import RobustScaler
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, 
    f1_score, roc_auc_score, log_loss
)
from sklearn.ensemble import HistGradientBoostingClassifier

warnings.filterwarnings('ignore')

# === CONFIGURATION ===
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
MODEL_DIR = BASE_DIR / "models"
MODEL_DIR.mkdir(exist_ok=True)

# Load config
with open(BASE_DIR / "config.yaml") as f:
    CONFIG = yaml.safe_load(f)


# =============================================================================
# PURGED WALK-FORWARD CV
# =============================================================================

class PurgedWalkForwardCV:
    """
    Time-series aware cross-validation with purging.
    
    - Expanding window: train grows, test moves forward
    - Purge window: gap between train and test (= max_hold)
    - Embargo: additional buffer after test
    """
    
    def __init__(self, n_splits: int = 5, purge_window: int = 24,
                 embargo_pct: float = 0.01, min_train_size: int = 5000):
        self.n_splits = n_splits
        self.purge_window = purge_window
        self.embargo_pct = embargo_pct
        self.min_train_size = min_train_size
    
    def split(self, X: pd.DataFrame):
        """Generate train/test indices with purging"""
        n_samples = len(X)
        embargo_size = int(n_samples * self.embargo_pct)
        
        # Calculate test size
        test_size = (n_samples - self.min_train_size) // self.n_splits
        
        for i in range(self.n_splits):
            # Test end
            test_end = n_samples - i * test_size
            test_start = test_end - test_size
            
            # Train end (with purge)
            train_end = test_start - self.purge_window
            train_start = 0
            
            if train_end < self.min_train_size:
                continue
            
            # Embargo after test
            embargo_end = min(test_end + embargo_size, n_samples)
            
            train_idx = list(range(train_start, train_end))
            test_idx = list(range(test_start, test_end))
            
            if len(train_idx) >= self.min_train_size and len(test_idx) > 0:
                yield train_idx, test_idx


# =============================================================================
# TRAINING PIPELINE
# =============================================================================

class WalkForwardTrainer:
    """
    Complete walk-forward training pipeline.
    
    Trains:
    1. Primary model: Predicts label (+1/-1/0)
    2. Meta model: Predicts P(primary is correct)
    
    Outputs:
    - Calibrated probability predictions
    - Model artifacts with SHA256
    - Per-fold performance metrics
    """
    
    def __init__(self, symbol: str, timeframe: str):
        self.symbol = symbol
        self.timeframe = timeframe
        
        # Load timeframe-specific config
        tf_config = CONFIG['labeling'].get(timeframe, CONFIG['labeling']['1h'])
        self.max_hold = tf_config['max_hold']
        
        # CV config
        cv_config = CONFIG['validation']
        self.n_splits = cv_config['n_splits']
        self.purge_window = cv_config['purge_window']
        self.embargo_pct = cv_config['embargo_pct']
        
        # Model config
        self.hyperparams = CONFIG['model']['hyperparameters'].copy()
        
        # Results storage
        self.fold_results: List[dict] = []
        self.primary_model = None
        self.meta_model = None
        self.scaler = None
        self.feature_names: List[str] = []
    
    def load_data(self) -> pd.DataFrame:
        """Load labeled and featured data"""
        path = DATA_DIR / f"{self.symbol}_{self.timeframe}_labeled.parquet"
        
        if not path.exists():
            # Try CSV
            path = DATA_DIR / f"{self.symbol}_{self.timeframe}.csv"
            if path.exists():
                df = pd.read_csv(path)
                df.columns = ['time', 'o', 'h', 'l', 'c', 'v']
                print(f"   ‚ö†Ô∏è Using raw data (run label_and_features.py first)")
                return df
            raise FileNotFoundError(f"Data not found: {path}")
        
        return pd.read_parquet(path)
    
    def prepare_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """Prepare features and labels"""
        # Get feature columns from schema
        schema_path = MODEL_DIR / f"feature_schema_{self.symbol}_{self.timeframe}.json"
        
        if schema_path.exists():
            with open(schema_path) as f:
                schema = json.load(f)
                self.feature_names = schema['features']
        else:
            # Infer features
            exclude = ['time', 'o', 'h', 'l', 'c', 'v', 'label', 'barrier_ret',
                       'exit_bar', 'exit_type', 'atr', 'purged']
            self.feature_names = [c for c in df.columns if c not in exclude]
        
        # Filter to available features
        available = [f for f in self.feature_names if f in df.columns]
        
        # Remove rows with NaN
        df = df.dropna(subset=available + ['label'])
        
        # Don't remove purged rows for training - use labels for 
        # rows that have valid triple-barrier outcomes
        # if 'purged' in df.columns:
        #     df = df[~df['purged']]
        
        # Filter to labeled rows only (non-zero labels)
        df = df[df['label'] != 0]
        
        X = df[available].copy()
        y = df['label'].copy()
        
        # Convert to binary for classification
        # +1 = profitable trade, 0/-1 = not profitable
        y_binary = (y == 1).astype(int)
        
        self.feature_names = available
        
        return X, y_binary
    
    def train_fold(self, X_train: pd.DataFrame, y_train: pd.Series,
                   X_test: pd.DataFrame, y_test: pd.Series,
                   fold: int) -> dict:
        """Train on single fold"""
        print(f"   üìä Fold {fold + 1}/{self.n_splits}")
        print(f"      Train: {len(X_train):,} | Test: {len(X_test):,}")
        
        # Scale features (fit on train only!)
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Save scaler from latest fold
        self.scaler = scaler
        
        # Train HistGradientBoostingClassifier
        model = HistGradientBoostingClassifier(
            max_iter=self.hyperparams.get('n_estimators', 500),
            max_depth=self.hyperparams.get('max_depth', 6),
            learning_rate=self.hyperparams.get('learning_rate', 0.05),
            min_samples_leaf=self.hyperparams.get('min_child_samples', 50),
            l2_regularization=self.hyperparams.get('reg_lambda', 0.1),
            random_state=42,
            early_stopping=True,
            n_iter_no_change=50,
            validation_fraction=0.1
        )
        model.fit(X_train_scaled, y_train)
        
        # Predictions
        y_pred = model.predict(X_test_scaled)
        y_proba = model.predict_proba(X_test_scaled)[:, 1]
        
        # Metrics
        metrics = {
            'fold': fold + 1,
            'train_size': len(X_train),
            'test_size': len(X_test),
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1': f1_score(y_test, y_pred, zero_division=0),
            'auc': roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) > 1 else 0.5,
        }
        
        # Win rate simulation
        test_with_preds = pd.DataFrame({
            'y_true': y_test.values,
            'y_pred': y_pred,
            'y_proba': y_proba
        })
        
        # Trade only when confident
        high_conf = test_with_preds[test_with_preds['y_proba'] >= CONFIG['signals']['confidence_threshold'] / 100]
        if len(high_conf) > 0:
            metrics['filtered_trades'] = len(high_conf)
            metrics['filtered_accuracy'] = (high_conf['y_true'] == high_conf['y_pred']).mean()
        else:
            metrics['filtered_trades'] = 0
            metrics['filtered_accuracy'] = 0
        
        print(f"      Accuracy: {metrics['accuracy']:.2%} | AUC: {metrics['auc']:.3f} | "
              f"Filtered: {metrics['filtered_trades']} trades @ {metrics['filtered_accuracy']:.2%}")
        
        self.fold_results.append(metrics)
        
        # Save latest model
        self.primary_model = model
        
        return metrics
    
    def train_meta_model(self, X: pd.DataFrame, y: pd.Series,
                          primary_preds: np.ndarray):
        """Train meta-labeling model"""
        print("   üîÆ Training meta-labeling model...")
        
        # Meta-label: did primary model predict correctly?
        y_meta = (y.values == primary_preds).astype(int)
        
        # Train on same features
        X_scaled = self.scaler.transform(X)
        
        meta_model = HistGradientBoostingClassifier(
            max_iter=200,
            max_depth=4,
            learning_rate=0.05,
            random_state=42,
            early_stopping=False
        )
        meta_model.fit(X_scaled, y_meta)
        
        # Accuracy
        meta_preds = meta_model.predict(X_scaled)
        meta_acc = accuracy_score(y_meta, meta_preds)
        print(f"      Meta accuracy: {meta_acc:.2%}")
        
        return meta_model
    
    def calibrate_model(self, X: pd.DataFrame, y: pd.Series):
        """Apply probability calibration"""
        print("   üìè Calibrating probabilities...")
        
        X_scaled = self.scaler.transform(X)
        
        calibrated = CalibratedClassifierCV(
            self.primary_model,
            method=CONFIG['model']['calibration']['method'],
            cv=3
        )
        calibrated.fit(X_scaled, y)
        
        return calibrated
    
    def run(self) -> dict:
        """Run complete walk-forward training"""
        print(f"\n{'='*60}")
        print(f"üéØ Walk-Forward Training: {self.symbol} {self.timeframe}")
        print(f"{'='*60}")
        
        # Load data
        df = self.load_data()
        print(f"   üìÇ Loaded {len(df):,} rows")
        
        # Prepare features
        X, y = self.prepare_data(df)
        print(f"   üìê Features: {len(self.feature_names)} | Samples: {len(X):,}")
        
        # Walk-forward CV
        cv = PurgedWalkForwardCV(
            n_splits=self.n_splits,
            purge_window=self.purge_window,
            embargo_pct=self.embargo_pct
        )
        
        print(f"\n   üîÑ Running {self.n_splits}-Fold Purged Walk-Forward CV")
        print(f"      Purge window: {self.purge_window} bars")
        
        all_preds = np.zeros(len(X))
        
        for fold, (train_idx, test_idx) in enumerate(cv.split(X)):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            
            metrics = self.train_fold(X_train, y_train, X_test, y_test, fold)
            
            # Store predictions for meta-labeling
            all_preds[test_idx] = self.primary_model.predict(
                self.scaler.transform(X_test)
            )
        
        # Aggregate results
        avg_metrics = {
            'avg_accuracy': np.mean([f['accuracy'] for f in self.fold_results]),
            'avg_auc': np.mean([f['auc'] for f in self.fold_results]),
            'avg_precision': np.mean([f['precision'] for f in self.fold_results]),
            'avg_recall': np.mean([f['recall'] for f in self.fold_results]),
            'avg_f1': np.mean([f['f1'] for f in self.fold_results]),
            'std_accuracy': np.std([f['accuracy'] for f in self.fold_results]),
        }
        
        print(f"\n   üìà Aggregate Results:")
        print(f"      Avg Accuracy: {avg_metrics['avg_accuracy']:.2%} ¬± {avg_metrics['std_accuracy']:.2%}")
        print(f"      Avg AUC: {avg_metrics['avg_auc']:.3f}")
        print(f"      Avg F1: {avg_metrics['avg_f1']:.3f}")
        
        # Train meta-model on full data
        valid_mask = all_preds != 0
        if valid_mask.sum() > 1000:
            self.meta_model = self.train_meta_model(
                X[valid_mask], y[valid_mask], all_preds[valid_mask].astype(int)
            )
        
        # Save models
        self.save_models(avg_metrics)
        
        return avg_metrics
    
    def save_models(self, metrics: dict):
        """Save model artifacts with manifest"""
        print(f"\n   üíæ Saving models...")
        
        # Generate model ID
        import pickle
        model_bytes = pickle.dumps(self.primary_model)
        model_id = hashlib.sha256(model_bytes).hexdigest()
        
        # Save primary model
        model_path = MODEL_DIR / f"primary_{self.symbol}_{self.timeframe}.pkl"
        joblib.dump(self.primary_model, model_path)
        
        # Save meta model
        if self.meta_model:
            meta_path = MODEL_DIR / f"meta_{self.symbol}_{self.timeframe}.pkl"
            joblib.dump(self.meta_model, meta_path)
        
        # Save scaler
        scaler_path = MODEL_DIR / f"scaler_{self.symbol}_{self.timeframe}.pkl"
        joblib.dump(self.scaler, scaler_path)
        
        # Create manifest
        manifest = {
            'model_id': f"sha256:{model_id[:16]}",
            'model_type': CONFIG['model']['type'],
            'symbol': self.symbol,
            'timeframe': self.timeframe,
            'created_at': datetime.now().isoformat(),
            
            # Training info
            'train_samples': sum(f['train_size'] for f in self.fold_results),
            'n_folds': len(self.fold_results),
            'purge_window': self.purge_window,
            
            # Hyperparameters
            'hyperparams': self.hyperparams,
            
            # Performance
            'metrics': metrics,
            'fold_results': self.fold_results,
            
            # Feature info
            'feature_count': len(self.feature_names),
            'feature_names': self.feature_names[:20],  # First 20 for manifest
            
            # Artifact paths
            'artifacts': {
                'primary_model': str(model_path),
                'scaler': str(scaler_path),
                'meta_model': str(MODEL_DIR / f"meta_{self.symbol}_{self.timeframe}.pkl") if self.meta_model else None
            }
        }
        
        manifest_path = MODEL_DIR / f"manifest_{self.symbol}_{self.timeframe}.json"
        with open(manifest_path, 'w') as f:
            json.dump(manifest, f, indent=2)
        
        print(f"      Model ID: {manifest['model_id']}")
        print(f"      Manifest: {manifest_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Walk-forward training')
    parser.add_argument('symbol', nargs='?', default='BTCUSDT', help='Symbol')
    parser.add_argument('timeframe', nargs='?', default='15m', help='Timeframe')
    parser.add_argument('--all', action='store_true', help='Train all')
    
    args = parser.parse_args()
    
    if args.all:
        for symbol in ['BTCUSDT', 'PAXGUSDT']:
            for tf in ['5m', '15m', '30m', '1h']:
                try:
                    trainer = WalkForwardTrainer(symbol, tf)
                    trainer.run()
                except Exception as e:
                    print(f"‚ùå {symbol} {tf}: {e}")
    else:
        trainer = WalkForwardTrainer(args.symbol, args.timeframe)
        trainer.run()
